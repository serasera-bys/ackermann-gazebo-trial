# Evaluation Results

Source artifacts:
- `artifacts/eval_report.json`
- `artifacts/latency_report.json`

| Metric | Value |
|---|---:|
| algorithm | gradient_boosting |
| rows | 2400 |
| accuracy | 0.9783 |
| f1 | 0.4348 |
| roc_auc | 0.9612 |
| confusion_matrix | [[582, 5], [8, 5]] |

Latency proxy (in-process `predict()` call, 500 samples):

| Metric | Value (ms) |
|---|---:|
| p50 | 0.1500 |
| p95 | 0.1958 |
| max | 0.4007 |

## Notes
- Current run used synthetic `cmapss_like.csv` generated by the trainer.
- F1 is lower than accuracy due to class imbalance (few positive failure labels).
- For production claim, add separate HTTP load-test latency over `POST /predict` outside sandbox.
